{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\"\"\"必要なモジュールの読み込み\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import clip\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "torch.Size([16, 3, 512, 512])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "targets should not be none when in training mode",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 99\u001b[0m\n\u001b[0;32m     96\u001b[0m texture_consistency_loss \u001b[38;5;241m=\u001b[39m TextureConsistencyLoss(images, reconstructed_image)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# 検出ブランチの損失関数を計算\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m detections \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m detection_loss \u001b[38;5;241m=\u001b[39m detector(images, targets)\n\u001b[0;32m    101\u001b[0m detection_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(loss \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m detection_loss\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[1;32mc:\\Users\\engineer\\Desktop\\CXR\\SSAD\\self-supervised\\demo\\detection.py:18\u001b[0m, in \u001b[0;36mFCOSDetector.forward\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, image):\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\engineer\\anaconda3\\envs\\ssl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\engineer\\anaconda3\\envs\\ssl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\engineer\\anaconda3\\envs\\ssl\\lib\\site-packages\\torchvision\\models\\detection\\fcos.py:577\u001b[0m, in \u001b[0;36mFCOS.forward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtargets should not be none when in training mode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m targets:\n",
      "File \u001b[1;32mc:\\Users\\engineer\\anaconda3\\envs\\ssl\\lib\\site-packages\\torch\\__init__.py:2041\u001b[0m, in \u001b[0;36m_assert\u001b[1;34m(condition, message)\u001b[0m\n\u001b[0;32m   2035\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(condition) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;129;01mand\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mhas_torch_function(\n\u001b[0;32m   2036\u001b[0m     (condition,)\n\u001b[0;32m   2037\u001b[0m ):\n\u001b[0;32m   2038\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mhandle_torch_function(\n\u001b[0;32m   2039\u001b[0m         _assert, (condition,), condition, message\n\u001b[0;32m   2040\u001b[0m     )\n\u001b[1;32m-> 2041\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m condition, message\n",
      "\u001b[1;31mAssertionError\u001b[0m: targets should not be none when in training mode"
     ]
    }
   ],
   "source": [
    "\"\"\"学習の実装\"\"\"\n",
    "from torchvision.datasets import CocoDetection\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from demo.data import CustomCompose\n",
    "from demo.simmim import MaskGenerator\n",
    "from demo.data import MyCocoDetection\n",
    "\n",
    "# 検出ブランチのデータセットの読み込み\n",
    "transform = CustomCompose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                transforms.Resize((512, 512))])\n",
    "\n",
    "detection_dataset = MyCocoDetection(root=\"dataset/detection\", annFile=\"dataset/detection/train_quadrant_enumeration_fdi.json\", transforms=transform)\n",
    "detection_dataloader = DataLoader(detection_dataset, batch_size=16, shuffle=True, collate_fn = lambda x: tuple(zip(*x)))\n",
    "\n",
    "\n",
    "# モデルの読み込み\n",
    "from demo.image_encoder import ResnetEncoder\n",
    "from demo.detection import FCOSDetector\n",
    "from demo.reconstruction import Recostruction\n",
    "\n",
    "encoder = ResnetEncoder()\n",
    "detector = FCOSDetector()\n",
    "recostruction = Recostruction(encoder_outchannels=2048)\n",
    "\n",
    "\n",
    "# 損失関数\n",
    "from demo.loss import ReconstructionLoss, TextureConsistencyLoss\n",
    "\n",
    "# オプティマイザー\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(\n",
    "    [\n",
    "        {\"params\": encoder.parameters(), \"lr\": 1e-4},\n",
    "        {\"params\": detector.parameters(), \"lr\": 1e-4},\n",
    "        {\"params\": recostruction.parameters(), \"lr\": 1e-4},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 学習ループ\n",
    "NUM_EPOCHS = 1000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# マスク生成器のインスタンス化\n",
    "mask_generator = MaskGenerator(batch_size=16)\n",
    "\n",
    "# モデルをデバイスに移動\n",
    "encoder.to(device)\n",
    "detector.to(device)\n",
    "recostruction.to(device)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    encoder.train()\n",
    "    detector.train()\n",
    "    recostruction.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    \n",
    "    for images, targets in detection_dataloader:\n",
    "        batch_size = 16\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # imagesをB,C,H,Wのテンソルに変換\n",
    "        images = torch.stack(images, dim=0)\n",
    "        print(images.shape)\n",
    "\n",
    "        # マスク生成器のインスタンス化\n",
    "        mask_generator = MaskGenerator(batch_size=batch_size)\n",
    "\n",
    "        # imageにマスクをかける\n",
    "        masks = mask_generator()\n",
    "        # 画像の形状に合わせてマスクをリシェイプ\n",
    "        masks = masks.unsqueeze(1)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        masked_images = images * (1 - masks)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # マスクをかけた画像をencoderに通す\n",
    "        features = encoder.forward(masked_images)\n",
    "\n",
    "        # 特徴量抽出された画像を復元\n",
    "        reconstructed_image = recostruction.forward(features)\n",
    "\n",
    "        # 再構築ブランチの損失関数を計算\n",
    "        reconstruction_loss = ReconstructionLoss(images, reconstructed_image)\n",
    "        texture_consistency_loss = TextureConsistencyLoss(images, reconstructed_image)\n",
    "\n",
    "        # 検出ブランチの損失関数を計算\n",
    "        detections = detector.forward(images)\n",
    "        detection_loss = detector(images, targets)\n",
    "        detection_loss = sum(loss for loss in detection_loss.values())\n",
    "\n",
    "        # 総損失を計算  \n",
    "        total_loss = reconstruction_loss + texture_consistency_loss + detection_loss\n",
    "\n",
    "        # 勾配を計算\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ロスを表示\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss.item()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
