{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\"\"\"必要なモジュールの読み込み\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import clip\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 画像の読み込み\u001b[39;00m\n\u001b[0;32m      5\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxrays/val_0.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m## 前処理\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "# 画像にマスクをかける\n",
    "from demo.simmim import MaskGenerator\n",
    "\n",
    "# 画像の読み込み\n",
    "image = cv2.imread(\"xrays/val_0.png\")\n",
    "image = cv2.resize(image, (512, 512))\n",
    "## 前処理\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "image = transform(image)\n",
    "mask = MaskGenerator(image)\n",
    "# マスクの生成\n",
    "masked_image = mask\n",
    "\n",
    "# 画像の表示\n",
    "## numpyに変換\n",
    "\n",
    "# image Encoderの実装\n",
    "from demo.image_encoder import ResnetEncoder\n",
    "\n",
    "encoder = ResnetEncoder()\n",
    "# imagetensorを(B, H, W, C)に変換\n",
    "image = image.unsqueeze(0)\n",
    "\n",
    "image = image.to(device)\n",
    "\n",
    "\n",
    "encoder.to(device)\n",
    "features = encoder.forward(image)\n",
    "print(features.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 511, 511)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特徴量抽出された画像を復元\n",
    "from demo.reconstruction import Recostruction\n",
    "\n",
    "recostruction = Recostruction(encoder_outchannels=2048)\n",
    "\n",
    "recostruction.to(device)\n",
    "\n",
    "features = features.to(device)\n",
    "\n",
    "reconstructed_image = recostruction.forward(features)\n",
    "\n",
    "# 画像の表示\n",
    "reconstructed_image = reconstructed_image.squeeze(0)\n",
    "reconstructed_image = reconstructed_image.detach().cpu().numpy()\n",
    "print(reconstructed_image.shape)\n",
    "\n",
    "reconstructed_image = np.transpose(reconstructed_image, (1, 2, 0))\n",
    "# 正規化を戻す\n",
    "\n",
    "cv2.imwrite(\"reconstructed_image.png\", reconstructed_image)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"学習の実装\"\"\"\n",
    "# データセットの読み込み\n",
    "from demo.data import UnlabelledDataset\n",
    "\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 再構築ブランチのデータセットの読み込み\n",
    "reconstruction_dataset = UnlabelledDataset(root=\"xrays/val\", transforms=transform)\n",
    "reconstruction_dataloader = DataLoader(reconstruction_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "# 検出ブランチのデータセットの読み込み\n",
    "detection_dataset = CocoDetection(root=\"xrays/val\", annFile=\"xrays/val.json\",transform=transform)\n",
    "detection_dataloader = DataLoader(detection_dataset, batch_size=16, shuffle=True, num_workers=4, collate_fn = lambda x: tuple(zip(*x)))\n",
    "\n",
    "\n",
    "# モデルの読み込み\n",
    "from demo.image_encoder import ResnetEncoder\n",
    "from demo.detection import FCOSDetector\n",
    "from demo.reconstruction import Recostruction\n",
    "\n",
    "encoder = ResnetEncoder()\n",
    "detector = FCOSDetector()\n",
    "recostruction = Recostruction(encoder_outchannels=2048)\n",
    "\n",
    "\n",
    "# 損失関数\n",
    "from demo.loss import ReconstructionLoss, TextureConsistencyLoss\n",
    "\n",
    "# オプティマイザー\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(\n",
    "    [\n",
    "        {\"params\": encoder.parameters(), \"lr\": 1e-4},\n",
    "        {\"params\": detector.parameters(), \"lr\": 1e-4},\n",
    "        {\"params\": recostruction.parameters(), \"lr\": 1e-4},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 学習ループ\n",
    "NUM_EPOCHS = 1000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# モデルをデバイスに移動\n",
    "encoder.to(device)\n",
    "detector.to(device)\n",
    "recostruction.to(device)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    encoder.train()\n",
    "    detector.train()\n",
    "    recostruction.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    \n",
    "    for images, targets in detection_dataloader:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # imageにマスクをかける\n",
    "        mask = MaskGenerator(image)\n",
    "        masked_image = mask\n",
    "\n",
    "        # マスクをかけた画像をencoderに通す\n",
    "        features = encoder.forward(masked_image)\n",
    "\n",
    "        # 特徴量抽出された画像を復元\n",
    "        reconstructed_image = recostruction.forward(features)\n",
    "\n",
    "        # 再構築ブランチの損失関数を計算\n",
    "        reconstruction_loss = ReconstructionLoss(image, reconstructed_image)\n",
    "        texture_consistency_loss = TextureConsistencyLoss(image, reconstructed_image)\n",
    "\n",
    "        # 検出ブランチの損失関数を計算\n",
    "        detections = detector.forward(image)\n",
    "        detection_loss = detector(images, targets)\n",
    "        detection_loss = sum(loss for loss in detection_loss.values())\n",
    "\n",
    "        # 総損失を計算  \n",
    "        total_loss = reconstruction_loss + texture_consistency_loss + detection_loss\n",
    "\n",
    "        # 勾配を計算\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ロスを表示\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss.item()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
